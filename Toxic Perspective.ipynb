{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c8ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from googleapiclient import discovery\n",
    "from perspective import PerspectiveAPI\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '' #Include Perspective API KEY\n",
    "\n",
    "p = PerspectiveAPI(API_KEY)\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n",
    "\n",
    "analyze_request = {\n",
    "  'comment': { 'text': 'This is a sample text for toxicity' },\n",
    "  'requestedAttributes': {'TOXICITY': {}, 'PROFANITY':{}}\n",
    "}\n",
    "\n",
    "response = client.comments().analyze(body=analyze_request).execute()\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a35c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_check = 'Check another text'\n",
    "txt_lang = 'en'\n",
    "try:\n",
    "    analyze_request = {\n",
    "        'comment': { 'text': txt_check },\n",
    "        'requestedAttributes': {'TOXICITY': {}, 'PROFANITY':{}, 'SEVERE_TOXICITY': {},\n",
    "                                'IDENTITY_ATTACK':{}, 'INSULT':{}, 'THREAT':{}},\n",
    "            'languages':txt_lang\n",
    "        }\n",
    "except:\n",
    "    print('Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b962b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_location = '' #Directory of IO dataset file\n",
    "file_name = '' #CSV File name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(path_location + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_lang = ['ar', 'zh', 'cs', 'nl', 'en', 'fr', 'de', 'hi', 'id', 'it', 'ja', 'ko', 'pl', 'pt', 'ru', 'es']\n",
    "df_data = df_data.loc[df_data.tweet_language.isin(supported_lang)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(tweet_df):\n",
    "    tweet_df['quoted_tweet_tweetid'] = tweet_df['quoted_tweet_tweetid'].astype('Int64')\n",
    "    tweet_df['retweet_tweetid'] = tweet_df['retweet_tweetid'].astype('Int64')\n",
    "    \n",
    "    tweet_type = []\n",
    "    for i in range(tweet_df.shape[0]):\n",
    "        if pd.notnull(tweet_df['quoted_tweet_tweetid'].iloc[i]):\n",
    "            if pd.notnull(tweet_df['retweet_tweetid'].iloc[i]):\n",
    "                if pd.notnull(tweet_df['in_reply_to_tweetid'].iloc[i]):\n",
    "                    continue\n",
    "                else:\n",
    "                    tweet_type.append('retweet')\n",
    "            else:\n",
    "                if pd.notnull(tweet_df['in_reply_to_tweetid'].iloc[i]):\n",
    "                    tweet_type.append('reply')\n",
    "                else:\n",
    "                    tweet_type.append('quoted')\n",
    "        else:\n",
    "            if pd.notnull(tweet_df['retweet_tweetid'].iloc[i]):\n",
    "                if pd.notnull(tweet_df['in_reply_to_tweetid'].iloc[i]):\n",
    "                    continue\n",
    "                else:\n",
    "                    tweet_type.append('retweet')\n",
    "            else:\n",
    "                if pd.notnull(tweet_df['in_reply_to_tweetid'].iloc[i]):\n",
    "                    tweet_type.append('reply')\n",
    "                else:\n",
    "                    tweet_type.append('original')\n",
    "    tweet_df['tweet_type'] = tweet_type\n",
    "    \n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    # Cleaning tweets in en language\n",
    "    # Removing RT Word from Messages\n",
    "    df['tweet_text']=df['tweet_text'].str.lstrip('RT')\n",
    "    df['tweet_text']=df['tweet_text'].str.replace( \"\\n\",'')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  \n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "\n",
    "#Message Clean Function\n",
    "def msg_clean(msg):\n",
    "    msg = re.sub(r'https?://\\S+|www\\.\\S+', \" \", msg)\n",
    "    msg = re.sub(r'@\\w+',' ',msg)\n",
    "    msg = re.sub('r<.*?>',' ', msg)\n",
    "    msg = remove_emoji(msg)\n",
    "    return msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = process_data(df_data)\n",
    "df_data = preprocess_text(df_data)\n",
    "df_data['updated_tweet_text'] = df_data['tweet_text'].astype(str).apply(lambda x: msg_clean(x))\n",
    "df_data = df_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773228e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_Toxic = []\n",
    "res_SevereToxic = []\n",
    "res_Profanity = []\n",
    "res_IDAttack = []\n",
    "res_Insult = []\n",
    "res_Threat = []\n",
    "tid2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(df_data)):\n",
    "    \n",
    "    txt_check = df_data.iloc[i].updated_tweet_text\n",
    "    txt_lang = df_data.iloc[i].tweet_language\n",
    "    try:\n",
    "        analyze_request = {\n",
    "          'comment': { 'text': txt_check },\n",
    "          'requestedAttributes': {'TOXICITY': {}, 'PROFANITY':{}, 'SEVERE_TOXICITY': {},\n",
    "                                 'IDENTITY_ATTACK':{}, 'INSULT':{}, 'THREAT':{}},\n",
    "            'languages':[txt_lang]\n",
    "        }\n",
    "\n",
    "\n",
    "        response = client.comments().analyze(body=analyze_request).execute()\n",
    "        \n",
    "        res_Toxic.append(response['attributeScores']['TOXICITY']['spanScores'][0]['score']['value'])\n",
    "        res_SevereToxic.append(response['attributeScores']['SEVERE_TOXICITY']['spanScores'][0]['score']['value'])\n",
    "        res_Profanity.append(response['attributeScores']['PROFANITY']['spanScores'][0]['score']['value'])\n",
    "        res_IDAttack.append(response['attributeScores']['IDENTITY_ATTACK']['spanScores'][0]['score']['value'])\n",
    "        res_Insult.append(response['attributeScores']['INSULT']['spanScores'][0]['score']['value'])\n",
    "        res_Threat.append(response['attributeScores']['THREAT']['spanScores'][0]['score']['value'])\n",
    "        tid2.append(df_data.iloc[i].tweetid)\n",
    "        \n",
    "\n",
    "    except:\n",
    "        res_Toxic.append(-1)\n",
    "        res_SevereToxic.append(-1)\n",
    "        res_Profanity.append(-1)\n",
    "        res_IDAttack.append(-1)\n",
    "        res_Insult.append(-1)\n",
    "        res_Threat.append(-1)\n",
    "        tid2.append(df_data.iloc[i].tweetid)\n",
    "    \n",
    "    time.sleep(0.05)\n",
    "    \n",
    "    if i%50000 == 1:\n",
    "        print(i)\n",
    "        df_pers2 = pd.DataFrame({'Tweet_ID': tid2, 'Toxic':res_Toxic, 'Severe_Toxic': res_SevereToxic,\n",
    "                        'Profanity': res_Profanity, 'Identity_Attack': res_IDAttack, \n",
    "                        'Insult': res_Insult, 'Threat': res_Threat})\n",
    "        df_pers2.to_csv('', index = False) #Store the File\n",
    "\n",
    "        \n",
    "df_pers2 = pd.DataFrame({'Tweet_ID': tid2, 'Toxic':res_Toxic, 'Severe_Toxic': res_SevereToxic,\n",
    "                        'Profanity': res_Profanity, 'Identity_Attack': res_IDAttack, \n",
    "                        'Insult': res_Insult, 'Threat': res_Threat})\n",
    "\n",
    "df_pers2.to_csv('', index = False) #Store the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04db96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
